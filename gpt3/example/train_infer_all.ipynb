{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXsEzHoqsPhP",
        "outputId": "d5e072d1-6539-4f58-dd35-7054108014d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.26.4.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.26.4-py3-none-any.whl size=67744 sha256=8489e4f68d71aa14f8035ff01e978ceda56124dae60f8e4aa11136439563e5bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/d8/4e/268f029bd3277c1dd9e8781a0e0296e0a63822665bfa2429fc\n",
            "Successfully built openai\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.26.4\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L15A4RoYsaZ-",
        "outputId": "7a1fa308-b41f-4ea8-a306-77e86f378438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your file contains 2 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
            "- More than a third of your `completion` column/key is uppercase. Uppercase completions tends to perform worse than a mixture of case encountered in normal language. We recommend to lower case the data if that makes sense in your domain. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "- All prompts end with suffix `. There are three fixed number tiles: \"$\", \"@\" and \".\". The count of \"$\" is 4, \".\" is 4, and \"@\" is 1.->`. This suffix seems very long. Consider replacing with a shorter suffix, such as ` ->`\n",
            "- All prompts start with prefix `The size of the level is 10 x 10. There is a base tile \"#\" with the count `. Fine-tuning doesn't require the instruction specifying the task, or a few-shot example scenario. Most of the time you should only add the input data into the prompt, and the desired output into the completion\n",
            "- All completions start with prefix ` ##########\n",
            "#`. Most of the time you should only add the output data into the completion, without any prefix\n",
            "- All completions end with suffix `#\\n##########\\n\\n. END`. This suffix seems very long. Consider replacing with a shorter suffix, such as `***`\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Recommended] Lowercase all your data in column/key `completion` [Y/n]: n\n",
            "- [Recommended] Remove prefix `The size of the level is 10 x 10. There is a base tile \"#\" with the count ` from all prompts [Y/n]: n\n",
            "- [Recommended] Remove prefix ` ##########\n",
            "#` from all completions [Y/n]: n\n",
            "\n",
            "You can use your file for fine-tuning:\n",
            "> openai api fine_tunes.create -t \"/content/drive/MyDrive/research/example_data.jsonl\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `. There are three fixed number tiles: \"$\", \"@\" and \".\". The count of \"$\" is 4, \".\" is 4, and \"@\" is 1.->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"#\\n##########\\n\\n. END\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 2.47 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ],
      "source": [
        "!openai tools fine_tunes.prepare_data -f './example_data.jsonl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WQIjLpLjszaj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"sk-...\"\n",
        "!set OPENAI_API_KEY=sk-..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtOicpdQtPz-",
        "outputId": "2744ded0-1a80-408e-f9bc-fc9471f5f5d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rUpload progress:   0% 0.00/791 [00:00<?, ?it/s]\rUpload progress: 100% 791/791 [00:00<00:00, 1.06Mit/s]\n",
            "Uploaded file from /content/drive/MyDrive/research/example_data.jsonl: file-7quiG7oy1nVUcynLJMljpN1v\n",
            "Created fine-tune: ft-gtTI6n6qeXpNaCeu1OaBIKUP\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-02-03 09:57:56] Created fine-tune: ft-gtTI6n6qeXpNaCeu1OaBIKUP\n",
            "[2023-02-03 09:58:31] Fine-tune costs $0.00\n",
            "[2023-02-03 09:58:31] Fine-tune enqueued. Queue number: 14\n",
            "[2023-02-03 10:00:07] Fine-tune is in the queue. Queue number: 13\n",
            "[2023-02-03 10:01:52] Fine-tune is in the queue. Queue number: 12\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-gtTI6n6qeXpNaCeu1OaBIKUP\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!openai api fine_tunes.create -t \"/content/drive/MyDrive/research/example_data.jsonl\" -m ada --n_epochs 1 --suffix \"example boxoban\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE89kONXxSDk",
        "outputId": "d3e0ba4a-c951-46c2-b0a4-d8d17007a306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-02-03 09:57:56] Created fine-tune: ft-gtTI6n6qeXpNaCeu1OaBIKUP\n",
            "[2023-02-03 09:58:31] Fine-tune costs $0.00\n",
            "[2023-02-03 09:58:31] Fine-tune enqueued. Queue number: 14\n",
            "[2023-02-03 10:00:07] Fine-tune is in the queue. Queue number: 13\n",
            "[2023-02-03 10:01:52] Fine-tune is in the queue. Queue number: 12\n",
            "[2023-02-03 10:12:31] Fine-tune is in the queue. Queue number: 11\n",
            "[2023-02-03 10:15:27] Fine-tune is in the queue. Queue number: 10\n",
            "[2023-02-03 10:17:12] Fine-tune is in the queue. Queue number: 9\n",
            "[2023-02-03 10:17:29] Fine-tune is in the queue. Queue number: 8\n",
            "[2023-02-03 10:17:56] Fine-tune is in the queue. Queue number: 7\n",
            "[2023-02-03 10:18:13] Fine-tune is in the queue. Queue number: 6\n",
            "[2023-02-03 10:19:27] Fine-tune is in the queue. Queue number: 5\n",
            "[2023-02-03 10:21:21] Fine-tune is in the queue. Queue number: 4\n",
            "[2023-02-03 10:21:55] Fine-tune is in the queue. Queue number: 3\n",
            "[2023-02-03 10:22:45] Fine-tune is in the queue. Queue number: 2\n",
            "[2023-02-03 10:23:20] Fine-tune is in the queue. Queue number: 1\n",
            "[2023-02-03 10:23:59] Fine-tune is in the queue. Queue number: 0\n",
            "[2023-02-03 10:26:24] Fine-tune started\n",
            "[2023-02-03 10:26:36] Completed epoch 1/1\n",
            "[2023-02-03 10:26:55] Server error. Returning to queue for retry\n",
            "[2023-02-03 10:28:51] Fine-tune is in the queue. Queue number: 8\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-gtTI6n6qeXpNaCeu1OaBIKUP\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!openai api fine_tunes.follow -i ft-gtTI6n6qeXpNaCeu1OaBIKUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kPp1FsutgNn",
        "outputId": "e2d141bd-eba3-4e76-f2cf-2856a43c1ebb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-6fnjZhb795vXDZ1YIHy6BqCWQ4JuB at 0x7f1fda4ccea0> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"length\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"text\": \" ##########\\n#AAAAAAAAAAAAAA#\\n#AAAAAAAAAAAAAA#\\n#AAAAAAAAAAAAAA#\\n#BAAAAAAAAAAAAB#\\n#BBAAAAAAAAAABB#\\n#BBBBAAAAAABBBB#\\n#BBBBBBBBBBBBBB#\\nJCBBBBBBBBBBBB#\\nJCCBBBBBBBBBBBB#\\nJCCCCCBBBBBBBBBJ\\nJCCCCCCBBBBBBBBJ\\n#CCCCCCCCBBBBBBJ\\n#CCCCCCCCBBBBBBJ\\n#CCCCCCCCBB\"\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1675420645,\n",
              "  \"id\": \"cmpl-6fnjZhb795vXDZ1YIHy6BqCWQ4JuB\",\n",
              "  \"model\": \"ada:ft-personal:level-gen-1-2023-01-31-07-15-28\",\n",
              "  \"object\": \"text_completion\",\n",
              "  \"usage\": {\n",
              "    \"completion_tokens\": 120,\n",
              "    \"prompt_tokens\": 67,\n",
              "    \"total_tokens\": 187\n",
              "  }\n",
              "}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import openai\n",
        "openai.Completion.create(\n",
        "  model=\"ada:ft-personal:level-gen-1-2023-01-31-07-15-28\",\n",
        "  prompt=\"The size of the level is 10 x 10. There is a base tile \\\"#\\\" with the count 77 and a space tile \\\" \\\" with the count 14. There are three fixed number tiles: \\\"$\\\", \\\"@\\\" and \\\".\\\". The count of \\\"$\\\" is 4, \\\".\\\" is 4, and \\\"@\\\" is 1.->\",\n",
        "  max_tokens=120,\n",
        "  temperature=1,\n",
        "  stop = [\". END\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RH2JZR9D2fge"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
